{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: humanfriendly in c:\\users\\a00017297\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (4.18)\n",
      "Requirement already satisfied: pyreadline; sys_platform == \"win32\" in c:\\users\\a00017297\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from humanfriendly) (2.1)\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto', random_state=0,\n",
      "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "                          verbose=0, warm_start=False) \n",
      "\n",
      "GradientBoostingRegressor(rmse): 3.1941117128039194 \n",
      "\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 8 seconds and 655.86 milliseconds\n",
      "{'alpha': 0.9, 'learning_rate': 0.1, 'loss': 'huber', 'n_estimators': 300} \n",
      "\n",
      "GradientBoostingRegressor(rmse): 3.0839764165411934 \n",
      "\n",
      "cross-validation rmse: 3 seconds and 187.82 milliseconds\n",
      "3.7929403445012064\n"
     ]
    }
   ],
   "source": [
    "# install humanfriendly if necessary\n",
    "!pip install humanfriendly\n",
    "\n",
    "import numpy as np, humanfriendly as hf, warnings, sys\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV,\\\n",
    "     cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_error(model, Xtest, ytest):\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return np.sqrt(mean_squared_error(ytest, y_pred)),\\\n",
    "           model.__class__.__name__\n",
    "\n",
    "def see_time(note):\n",
    "    end = time.perf_counter()\n",
    "    elapsed = end - start\n",
    "    print (note,\n",
    "           hf.format_timespan(elapsed, detailed=True))\n",
    "\n",
    "def get_cross(model, data, target, groups=10):\n",
    "    return cross_val_score(model, data, target, cv=groups,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    br = '\\n'\n",
    "    if not sys.warnoptions:\n",
    "        warnings.simplefilter('ignore')\n",
    "    X = np.load('data/X_boston.npy')\n",
    "    y = np.load('data/y_boston.npy')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(random_state=0)\n",
    "    print (gbr, br)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    rmse, name = get_error(gbr, X_test, y_test)\n",
    "    print (name + '(rmse):', end=' ')\n",
    "    print (rmse, br)\n",
    "    loss = ['ls', 'lad', 'huber']\n",
    "    lr = [1e-2, 1e-1, 1e-0]\n",
    "    n_est = [150, 200, 300, 500]\n",
    "    alpha = [0.9]\n",
    "    params = {'loss': loss, 'learning_rate': lr,\n",
    "              'n_estimators': n_est, 'alpha': alpha}\n",
    "    grid = GridSearchCV(gbr, params, cv=5, n_jobs=-1,\n",
    "                        verbose=1, refit=False)\n",
    "    start = time.perf_counter()\n",
    "    grid.fit(X_train, y_train)\n",
    "    see_time('training time:')\n",
    "    bp = grid.best_params_\n",
    "    print (bp, br)\n",
    "    gbr = GradientBoostingRegressor(**bp, random_state=0)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    rmse, name = get_error(gbr, X_test, y_test)\n",
    "    print (name + '(rmse):', end=' ')\n",
    "    print (rmse, br)\n",
    "    start = time.perf_counter()\n",
    "    scores = get_cross(gbr, X, y)\n",
    "    see_time('cross-validation rmse:')\n",
    "    rmse = np.sqrt(np.mean(scores) * -1)\n",
    "    print (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
